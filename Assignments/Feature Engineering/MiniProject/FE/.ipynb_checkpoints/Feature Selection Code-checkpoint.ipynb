{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two wide range of algorithms for feature selection:\n",
    "1. Filter-based\n",
    "2. Wrapper-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Filter-based\n",
    "In this approach, we use a statistical measure to assign each feature a score based on this. Generally, this is a univariate approach i.e., we either select/drop a feature based on the score that we assigned to it.\n",
    "\n",
    "Examples of popular statistical measures:\n",
    "1. Chi-Squared\n",
    "2. Information Gain\n",
    "3. Pearson Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Chi-Sqaured\n",
    "Used for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Values\n",
      "  Mean of the integrated profile                  140.562500\n",
      " Standard deviation of the integrated profile     55.683782\n",
      " Excess kurtosis of the integrated profile        -0.234571\n",
      " Skewness of the integrated profile               -0.699648\n",
      " Mean of the DM-SNR curve                          3.199833\n",
      " Standard deviation of the DM-SNR curve           19.110426\n",
      " Excess kurtosis of the DM-SNR curve               7.975532\n",
      " Skewness of the DM-SNR curve                     74.242225\n",
      "Name: 0, dtype: float64\n",
      "Converted Values\n",
      "  Mean of the integrated profile                  144\n",
      " Standard deviation of the integrated profile     59\n",
      " Excess kurtosis of the integrated profile         3\n",
      " Skewness of the integrated profile                3\n",
      " Mean of the DM-SNR curve                          7\n",
      " Standard deviation of the DM-SNR curve           23\n",
      " Excess kurtosis of the DM-SNR curve              11\n",
      " Skewness of the DM-SNR curve                     78\n",
      "Name: 0, dtype: int32\n",
      "Chi-2 Scores [ 46580.97924933   2214.41897196   3029.97786074  65502.2391493\n",
      " 155016.6773539   54975.01782023   4719.83030129 125842.87665508]\n",
      "p values [0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "X = pd.read_csv(\"pulsar_features.csv\")\n",
    "y = pd.read_csv(\"pulsar_target.csv\")\n",
    "\n",
    "print(\"Actual Values\\n\",X.iloc[0,:])\n",
    "# Convert the dataset to categorical\n",
    "X = X+4\n",
    "X = X.astype(int)\n",
    "# X.to_csv(\"discretized_pulsar_features.csv\",index=False)\n",
    "print(\"Converted Values\\n\",X.iloc[0,:])\n",
    "\n",
    "chi2_scores, p_values = chi2(X,y)\n",
    "print(\"Chi-2 Scores\",chi2_scores)\n",
    "print(\"p values\",p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**<br>\n",
    "> Using *chi2* function removes the features that are the most likely to be independent of the target class and therefore irrelevant for classification.\n",
    "* Higher the value of chi2 --> More dependence\n",
    "* Simply put, it determines if the association between two categorical variables of the sample would reflect their real association in the population.\n",
    "\n",
    "**Further Reference**\n",
    "1. https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#examples-using-sklearn-feature-selection-chi2\n",
    "2. https://en.wikipedia.org/wiki/Chi-squared_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mutual Information Gain\n",
    "Used for continuous/real features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Values\n",
      "  Mean of the integrated profile                  140.562500\n",
      " Standard deviation of the integrated profile     55.683782\n",
      " Excess kurtosis of the integrated profile        -0.234571\n",
      " Skewness of the integrated profile               -0.699648\n",
      " Mean of the DM-SNR curve                          3.199833\n",
      " Standard deviation of the DM-SNR curve           19.110426\n",
      " Excess kurtosis of the DM-SNR curve               7.975532\n",
      " Skewness of the DM-SNR curve                     74.242225\n",
      "Name: 0, dtype: float64\n",
      "Converted Values\n",
      "  Mean of the integrated profile                  140.562500\n",
      " Standard deviation of the integrated profile     55.683782\n",
      " Excess kurtosis of the integrated profile        -0.234571\n",
      " Skewness of the integrated profile               -0.699648\n",
      " Mean of the DM-SNR curve                          3.199833\n",
      " Standard deviation of the DM-SNR curve           19.110426\n",
      " Excess kurtosis of the DM-SNR curve               7.975532\n",
      " Skewness of the DM-SNR curve                     74.242225\n",
      "Name: 0, dtype: float64\n",
      "Information Gain Values [0.19163503 0.08827766 0.22643797 0.19451223 0.11482367 0.11924799\n",
      " 0.11339291 0.11506427]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X = pd.read_csv(\"pulsar_features.csv\")\n",
    "y = pd.read_csv(\"pulsar_target.csv\")\n",
    "\n",
    "print(\"Actual Values\\n\",X.iloc[0,:])\n",
    "# Convert the dataset to categorical\n",
    "# X = X*100\n",
    "# X = X.astype(int)\n",
    "print(\"Converted Values\\n\",X.iloc[0,:])\n",
    "\n",
    "mutual_info_gain_values = mutual_info_classif(X,y,discrete_features=False,random_state=42)\n",
    "\n",
    "print(\"Information Gain Values\",mutual_info_gain_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\aruna\\anaconda3\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from mlxtend) (0.20.3)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from mlxtend) (40.8.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from mlxtend) (1.16.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from mlxtend) (0.13.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from mlxtend) (0.24.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from mlxtend) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2018.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aruna\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas>=0.24.2->mlxtend) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "#if mlxtend is not available install befor exectuting the wrapper method\n",
    "! pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "> We can see that both the methods are in compliance with each other i.e, last 2 features are better features compared to the first two.\n",
    "* Higher value of Info gain --> BETTER\n",
    "\n",
    "**Further Reference**\n",
    "1. https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif\n",
    "2. http://www.scholarpedia.org/article/Mutual_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Wrapper-based\n",
    "In this approach, we make a selection (subset) among the available features and create a predictive model. We assign each selection a score based on the accuracy of the predictive model.\n",
    "There are many ways of making a selection, depending on the process\n",
    "\n",
    "1. Methodical (best-first search)\n",
    "2. Stochastic (random hill-climbing)\n",
    "3. based on Heuristics (forward/backward feature selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Selection (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Values\n",
      "  Mean of the integrated profile                  140.562500\n",
      " Standard deviation of the integrated profile     55.683782\n",
      " Excess kurtosis of the integrated profile        -0.234571\n",
      " Skewness of the integrated profile               -0.699648\n",
      " Mean of the DM-SNR curve                          3.199833\n",
      " Standard deviation of the DM-SNR curve           19.110426\n",
      " Excess kurtosis of the DM-SNR curve               7.975532\n",
      " Skewness of the DM-SNR curve                     74.242225\n",
      "Name: 0, dtype: float64\n",
      "Best 4 features:  (1, 2, 3, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X = pd.read_csv(\"pulsar_features.csv\")\n",
    "y = pd.read_csv(\"pulsar_target.csv\")\n",
    "\n",
    "print(\"Actual Values\\n\",X.iloc[0,:])\n",
    "\n",
    "# Create the sbs object and select best 4 features\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "# the param forward when set to False will do sequential backward selection\n",
    "sbs = SFS(knn,\n",
    "           k_features=4,\n",
    "           forward=False,\n",
    "           scoring='accuracy')\n",
    "\n",
    "sbs = sbs.fit(X, y)\n",
    "print(\"Best 4 features: \",sbs.k_feature_idx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**<br>\n",
    "At each step we are finding one worst feature and removing it, so the first feature that will be removed will have last rank and vice versa.\n",
    "\n",
    "The ranking at each step is given using the accuracy score of the predictive model that we use. Here, we used a **KNeighborsClassifier** that classifies the points. We can use any of the classification models for this purpose.\n",
    "\n",
    "We can also observe that the best 4 features are in compliance with the values of information gain, so all the methods are different approaches and do not change the ground truth or characteristics of the dependencies between features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
